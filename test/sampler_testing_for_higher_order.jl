using MacroModelling
import Turing, StatsPlots
import LinearAlgebra as ‚Ñí

@model RBC begin
	K[0] = (1 - Œ¥) * K[-1] + I[0]
	Y[0] = Z[0] * K[-1]^Œ±
	Y[0] = C[0] + I[0]
	1 / C[0]^Œ≥ = Œ≤ / C[1]^Œ≥ * (Œ± * Y[1] / K[0] + (1 - Œ¥))
	Z[0] = (1 - œÅ) + œÅ * Z[-1] + œÉ * œµ[x]
end


@parameters RBC verbose = true begin 
    œÉ = 0.01
    Œ± = 0.5
    Œ≤ = 0.95
    œÅ = 0.2
    Œ¥ = 0.02
    Œ≥ = 1
end

get_SS(RBC)

# plot_irf(RBC)

get_solution(RBC)



Turing.@model function loglikelihood_function(m)
    œÉ     ~ MacroModelling.Beta(0.01, 0.02, ŒºœÉ = true)
    Œ±     ~ MacroModelling.Beta(0.5, 0.1, ŒºœÉ = true)
    Œ≤     ~ MacroModelling.Beta(0.95, 0.01, ŒºœÉ = true)
    œÅ     ~ MacroModelling.Beta(0.2, 0.1, ŒºœÉ = true)
    Œ¥     ~ MacroModelling.Beta(0.02, 0.05, ŒºœÉ = true)
    Œ≥     ~ Turing.Normal(1, 0.05)
    
    Turing.@addlogprob! sum(get_solution(m,[œÉ, Œ±, Œ≤, œÅ, Œ¥, Œ≥])[2]) / 1e8
end

# using LinearAlgebra

# Z‚ÇÅ‚ÇÅ = randn(10,10)
# ZÃÇ‚ÇÅ‚ÇÅ = svd(Z‚ÇÅ‚ÇÅ)
# ZÃÇ‚ÇÅ‚ÇÅ |>inv

# ZÃÇ‚ÇÅ‚ÇÅ.S .|> inv
# ZÃÇ‚ÇÅ‚ÇÅ.Vt |> inv

# (ZÃÇ‚ÇÅ‚ÇÅ.U * inv(diagm(ZÃÇ‚ÇÅ‚ÇÅ.S)) * ZÃÇ‚ÇÅ‚ÇÅ.Vt)'
# inv(Z‚ÇÅ‚ÇÅ)

# Z‚ÇÇ‚ÇÅ = randn(10,10)

# D      = Z‚ÇÇ‚ÇÅ / ZÃÇ‚ÇÅ‚ÇÅ
# D      = Z‚ÇÇ‚ÇÅ / Z‚ÇÅ‚ÇÅ



loglikelihood = loglikelihood_function(RBC)


n_samples = 10

Turing.setadbackend(:forwarddiff)

# using Zygote
# Turing.setadbackend(:zygote)
samps = Turing.sample(loglikelihood, Turing.NUTS(), n_samples, progress = true)#, init_params = sol)




Turing.@model function loglikelihood_second_order_function(m)
    œÉ     ~ MacroModelling.Beta(0.01, 0.02, ŒºœÉ = true)
    Œ±     ~ MacroModelling.Beta(0.5, 0.1, ŒºœÉ = true)
    Œ≤     ~ MacroModelling.Beta(0.95, 0.01, ŒºœÉ = true)
    œÅ     ~ MacroModelling.Beta(0.2, 0.1, ŒºœÉ = true)
    Œ¥     ~ MacroModelling.Beta(0.02, 0.05, ŒºœÉ = true)
    Œ≥     ~ Turing.Normal(1, 0.05)
    soll = get_solution(m,[œÉ, Œ±, Œ≤, œÅ, Œ¥, Œ≥], algorithm = :second_order)
    println(soll[end])
    Turing.@addlogprob! sum(soll[3]) / 1e6
end


loglikelihood_second_order = loglikelihood_second_order_function(RBC)

samps = Turing.sample(loglikelihood_second_order, Turing.NUTS(), n_samples, progress = true)#, init_params = sol)




solution = get_solution(RBC, RBC.parameter_values, algorithm = :second_order)

Turing.@model function loglikelihood_scaling_function(m, data, observables)
    œÉ     ~ MacroModelling.Beta(0.01, 0.02, ŒºœÉ = true)
    Œ±     ~ MacroModelling.Beta(0.5, 0.1, ŒºœÉ = true)
    Œ≤     ~ MacroModelling.Beta(0.95, 0.01, ŒºœÉ = true)
    œÅ     ~ MacroModelling.Beta(0.2, 0.1, ŒºœÉ = true)
    Œ¥     ~ MacroModelling.Beta(0.02, 0.05, ŒºœÉ = true)
    Œ≥     ~ Turing.Normal(1, 0.05)
    
    initial_conditions ~ Turing.filldist(Turing.TDist(4),m.timings.nPast_not_future_and_mixed) # Initial conditions 

    solution = get_solution(m, [œÉ, Œ±, Œ≤, œÅ, Œ¥, Œ≥], algorithm = :second_order)

    if solution[end] != true
        return Turing.@addlogprob! Inf
    end

    ùêí‚ÇÅ = hcat(solution[2][:,1:m.timings.nPast_not_future_and_mixed], zeros(m.timings.nVars), solution[2][:,m.timings.nPast_not_future_and_mixed+1:end])

    œµ_draw ~ Turing.filldist(Turing.TDist(4), m.timings.nExo * size(data, 2)) #Shocks are t-distributed!

    œµ = reshape(œµ_draw, m.timings.nExo,  size(data, 2))

    state = zeros(typeof(initial_conditions[1]),m.timings.nVars, size(data, 2))

    # state[m.timings.past_not_future_and_mixed_idx,1] .= initial_conditions

    aug_state = [initial_conditions
    1 
    œµ[:,1]]
    state[:,1] .=  ùêí‚ÇÅ * aug_state + solution[3] * ‚Ñí.kron(aug_state, aug_state) / 2 

    for t in 2:size(data, 2)
        aug_state = [state[m.timings.past_not_future_and_mixed_idx,t-1]
                    1 
                    œµ[:,t-1]]
        state[:,t] .=  ùêí‚ÇÅ * aug_state + solution[3] * ‚Ñí.kron(aug_state, aug_state) / 2 
    end

    observables_index = sort(indexin(observables, m.timings.var))

    state_deviations = data[:,2:end] - state[observables_index,2:end]

    Turing.@addlogprob! sum([Turing.logpdf(Turing.MvNormal(‚Ñí.Diagonal(ones(size(state_deviations,1)))), state_deviations[:,t]) for t in 1:size(data, 2)-1])
end


data=[ 0.062638   0.053282    0.00118333  0.442814   0.300381  0.150443  0.228132   0.382626   -0.0122483   0.0848671  0.0196158   0.197779    0.782655  0.751345   0.911694   0.754197   0.493297    0.0265917   0.209705    0.0876804;
-0.0979824  0.0126432  -0.12628     0.161212  -0.109357  0.120232  0.0316766  0.0678017  -0.0371438  -0.162375  0.0574594  -0.0564989  -0.18021   0.0749526  0.132553  -0.135002  -0.0143846  -0.0770139  -0.0295755  -0.0943254]



# AA = spzeros(10,10)
# AA[1:3,5:7] .= 1

# AA * Real[rand(10)...]


n_samples = 100

loglikelihood_scaling = loglikelihood_scaling_function(RBC, data,[:K,:Z])

samps = Turing.sample(loglikelihood_scaling, Turing.NUTS(), n_samples, progress = true)#, init_params = sol)

# m = RBC



# solution = get_solution(m, m.parameter_values, algorithm = :second_order)

# ùêí‚ÇÅ = hcat(solution[2][:,1:m.timings.nPast_not_future_and_mixed], zeros(m.timings.nVars), solution[2][:,m.timings.nPast_not_future_and_mixed+1:end])

# t=2


# state = zeros(Real,m.timings.nVars, size(data, 2)+1)
# œµ = zeros( m.timings.nExo,  size(data, 2))
# aug_state = [state[m.timings.past_not_future_and_mixed_idx,t-1]
# 1 
# œµ[:,t-1]]
# state[:,t] =  ùêí‚ÇÅ * aug_state + solution[3] * Real[‚Ñí.kron(aug_state, aug_state)...] / 2 


# observables = :K

# solution = get_solution(RBC, RBC.parameter_values, algorithm = :second_order)
# solution[3]